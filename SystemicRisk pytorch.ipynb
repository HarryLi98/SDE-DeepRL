{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=5, edgeitems=10, linewidth=1000, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carmona problem\n",
    "\n",
    "We consider a stochastic differential game with $N$ players, and we denote by $\\mathcal{I} := {1, 2, \\dots, N}$ the set of players. Let $T$ be a finite time horizon. At each time $t \\in [0, T]$, player $i \\in \\mathcal{I}$ has a state $X_{t}^{i} \\in \\mathbb{R}$ and takes an action $\\alpha_{t}^{i} \\in \\mathbb{R}$. The dynamics of the controlled state process $X_{i}$ on $[0, T]$ are given by:\n",
    "\n",
    "$$\\mathrm{d} X_t^i=\\left[a\\left(\\bar{X}_t-X_t^i\\right)+\\alpha_t^i\\right] \\mathrm{d} t+\\sigma\\left(\\rho \\mathrm{d} W_t^0+\\sqrt{1-\\rho^2} \\mathrm{~d} W_t^i\\right)$$\n",
    "\n",
    "where $\\boldsymbol{W}:=\\left[W^0, W^1, \\ldots, W^N\\right]$ are ($N+1$) $m$-dimensional independent Brownian motions, with $W^{i}$ the individual noises and $W^{0}$ the common noise.\n",
    "\n",
    "Given a set of strategies ($\\bold{\\alpha}_{t})_{t \\in [0, T]}$, the cost associated to player $i$ is of the form\n",
    "$$ J^{i}(\\alpha): \\alpha \\mapsto \\mathbb{E}\\left[\\int_0^T f^{i}\\left(t, X_t, \\alpha_{t}\\right) dt+g^{i}(X_T)\\right], $$\n",
    "\n",
    "Here $f^i:[0, T] \\times \\mathbb{R}^N \\times \\mathbb{R}^N \\rightarrow \\mathbb{R}$ denotes the running cost, and $g^i: \\mathbb{R}^N \\rightarrow \\mathbb{R}$ the terminal cost, where:\n",
    "$$f^i(t, \\boldsymbol{x}, \\boldsymbol{\\alpha})=\\frac{1}{2}\\left(\\alpha^i\\right)^2-q \\alpha^i\\left(\\bar{x}-x^i\\right)+\\frac{\\epsilon}{2}\\left(\\bar{x}-x^i\\right)^2$$\n",
    "$$g^i(\\boldsymbol{x})=\\frac{c}{2}\\left(\\bar{x}-x^i\\right)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the above problem using direct parameterization methods. For simplicity, we assume that there is no common noise, so the dynamics of $X_{i}$ on $[0, T]$ are given by:\n",
    "\n",
    "$$\\mathrm{d} X_t^i=\\left[a\\left(\\bar{X}_t-X_t^i\\right)+\\alpha_t^i\\right] \\mathrm{d}t+\\sigma\\mathrm{~d} W_t^i$$\n",
    "\n",
    "We approximate the dynamics and the expected cost by discretized versions:\n",
    "$$\\check{X}_{t_{n+1}}=\\check{X}_{t_n} + [a\\left(\\check{X}_{t_n} - \\check{X}^{i}_{t_n}\\right) + \\alpha^{i}_{t_n}] \\Delta t + \\sigma \\Delta \\check{W}_{t_n}, $$\n",
    "$$\\mathbb{E}\\left[\\sum_{n=0}^{N_T-1} f\\left(t_n, \\check{X}_{t_n}, \\alpha_{t_n}\\right) \\Delta t+g\\left(\\check{X}_T\\right)\\right], $$\n",
    "where $\\Delta \\check{W}_{t_n}=\\check{W}_{t_{n+1}}-\\check{W}_{t_n}$ are i.i.d random variables with distribution $\\Delta\\check{W} \\sim \\mathcal{N}\\left(0, \\Delta t\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate the control at each time step $\\alpha_{t_{n}}$ by a feedforward neural network $\\alpha_{t_{n}}(.; \\theta_{n})$, taking inputs $\\check{X}_{t_n}$, where $\\theta_{n}$ denotes all neural network's parameters at time $t_{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma = 0.2\n",
    "q = 1\n",
    "a = 1\n",
    "eps = 1.5\n",
    "rho = 0.2 # 0.2\n",
    "c = 1\n",
    "R = a**2 + 2*a*q + eps\n",
    "delta_p = -(a+q) + np.sqrt(R)\n",
    "delta_m = -(a+q) - np.sqrt(R)\n",
    "T = 1\n",
    "N_T = 5 # Number of subintervals on [0, T]\n",
    "N = 2 # Number of players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate Brownian increments, $(\\Delta\\check{W}^{i}_{n})_{i=1,\\dots,N, n=0,\\dots,N_{T}-1}$, which are i.i.d random variables with Gaussian distribution: $\\Delta\\check{W} \\sim \\mathcal{N}\\left(0, \\Delta t\\right)$.\n",
    "\n",
    "We discretise the unit time interval into 100 steps, so $\\Delta t = \\frac{T}{N} = \\frac{1}{100}$.\n",
    "\n",
    "We include the antithetic variates to reduce the variation of our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMIncrements(B, N_T, T=1):\n",
    "    \"\"\"Generate Brownian Motion increments\n",
    "\n",
    "    Args:\n",
    "        B: Number of sample paths\n",
    "        N: Number of increments. Defaults to 100.\n",
    "        T: Maximum time interval. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        Discretised Brownian path with antithetic variates\n",
    "    \"\"\"\n",
    "    dat = torch.randn(B, N_T, 1)*np.sqrt(T/N_T)\n",
    "    return torch.cat([dat, -dat], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_simulation(x, xbar, alpha, dw):\n",
    "    \"\"\"Simulate one step of the dynamics of X\n",
    "\n",
    "    Args:\n",
    "        x: _description_\n",
    "        m: _description_\n",
    "        alpha: _description_\n",
    "        dw: Brownian motion interval\n",
    "\n",
    "    Returns:\n",
    "        x_{t+1}\n",
    "    \"\"\"\n",
    "    dt = T/N_T\n",
    "    return x + (a*(xbar-x)+alpha)*dt + sigma*dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta(t):\n",
    "    numerator = -(eps-q**2)*(np.exp((delta_p-delta_m)*(T-t))-1)\\\n",
    "                -c*(delta_p*np.exp((delta_p - delta_m)*(T-t)) - delta_m)\n",
    "    denominator = delta_m*np.exp((delta_p-delta_m)*(T-t))-delta_p \\\n",
    "                    -c*(np.exp((delta_p-delta_m)*(T-t)) -1)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(w, cn, initial):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        m -- tensor(batch, N+1, dim), distribution interaction\n",
    "        w -- tensor(batch, N, dim), brownian increments\n",
    "        cn -- tensor(batch, N+1, dim), common noise\n",
    "        initial -- tensor(batch, 1, dim), starting point, has initial distribution mu_0\n",
    "    return:\n",
    "        X -- tensor(batch, N+1, dim), benchmark paths, no extra time dimension\n",
    "    \"\"\"\n",
    "    dt = T/N_T\n",
    "    batch, _, dim = w.size()\n",
    "    \n",
    "    X = torch.zeros(batch, N_T+1, dim)\n",
    "    X[:, 0, :] = initial\n",
    "    alpha = torch.zeros(batch, N_T, 1)\n",
    "    for i in range(1, N_T+1):\n",
    "        m = torch.mean(initial) + rho*sigma*cn[:, i]\n",
    "        alpha = (q + eta(dt*i-dt))*(m-X[:, i-1])\n",
    "        X[:, i, :] = one_step_simulation(X[:, i-1, :], m, alpha, w[:, i-1, :], cn[:, i]-cn[:, i-1])\n",
    "        alpha[:, i-1] = alpha\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sample paths to generate\n",
    "B = 2**10\n",
    "\n",
    "# Generate Brownian increments\n",
    "bm = BMIncrements(B//2, N_T, T=1)\n",
    "\n",
    "# Generate common noise, w0\n",
    "w_cn = BMIncrements(B//2, N_T, T=1)\n",
    "w0 = torch.zeros(B, N_T+1, 1)\n",
    "for i in range(1, N_T+1):\n",
    "    w0[:, i] = w0[:, i-1] + w_cn[:, i-1]\n",
    "bms = torch.utils.data.TensorDataset(bm, w0)\n",
    "bmDataLoader = torch.utils.data.DataLoader(bms, batch_size=2**7)\n",
    "\n",
    "alpha_0 = 0 # Initial guess of optimal strategies\n",
    "initial = torch.zeros(B, 1) # Initial, X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, xbar, alpha):\n",
    "    \"\"\"The running cost at time t\n",
    "\n",
    "    Args:\n",
    "        x: State at time t\n",
    "        xbar: Mean at time t\n",
    "        alpha: Control at time t\n",
    "    \"\"\"\n",
    "    return 0.5*alpha**2 - q*alpha*(xbar-x) + 0.5*eps*(xbar-x)**2\n",
    "\n",
    "def g(x, xbar):\n",
    "    \"\"\"Final time penalty\n",
    "\n",
    "    Args:\n",
    "        x: State of player i at time T\n",
    "        xbar: Mean at time T\n",
    "    \"\"\"\n",
    "    return c/2*(xbar-x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(alpha, ):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sample paths:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Neural network architecture parameters\n",
    "num_input_nodes = I\n",
    "num_output_nodes = I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural networks for each player\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='ReLU', input_shape=(num_input_nodes,), kernel_initializer=tf.keras.initializers.GlorotNormal),\n",
    "    tf.keras.layers.Dense(64, activation='ReLU'),\n",
    "    tf.keras.layers.Dense(num_output_nodes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='ReLU', input_shape=(num_input_nodes,), kernel_initializer=tf.keras.initializers.GlorotNormal),\n",
    "    tf.keras.layers.Dense(64, activation='ReLU'),\n",
    "    tf.keras.layers.Dense(num_output_nodes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "\n",
    "# Adam optimizer\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.experimental.Adam(learning_rate=lr, amsgrad=True, jit_compile=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    loss='mse'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64096634d8a8f11c08af37fa8607cc0f39c2d02dbc4ea7e4f55c2659a719043f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
